upplement Synonym Search

This project builds a multilingual AI model that finds the canonical (official) supplement or ingredient names based on synonyms in English, Swedish, and Latin.
It uses SentenceTransformers for semantic embeddings, FAISS for fast vector search, and a blended fuzzy-semantic scoring system for better accuracy.

ğŸš€ Features

Multilingual embeddings (English / Swedish / Latin)

Pre-computed embedding space â†’ ğŸ§© no retraining required

Cached FAISS index for instant search

Canonical-only training option (uses only official names)

Clean, normalized dataset built from pharmaceutical & novel-food sources

Command-line and notebook workflows

ğŸ“‚ Project structure
supplement-synonym-search/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ cleaned_supplements_highacc.csv        # Clean, normalized dataset
â”‚   â”œâ”€â”€ embeddings_canonical.npy               # Precomputed canonical embeddings
â”‚   â”œâ”€â”€ index_canonical.faiss                  # FAISS index for instant vector search
â”‚   â”œâ”€â”€ index_lookup_canonical.csv             # Lookup table for canonical names
â”‚   â””â”€â”€ index_meta_canonical.json              # Metadata (model name, row count)
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ data_processing.ipynb                  # Preprocessing pipeline
â”‚   â””â”€â”€ ingredient_check.ipynb                 # Demo & search interface
â”‚
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore

âš¡ Quick start
1ï¸âƒ£ Install dependencies
pip install -r requirements.txt

2ï¸âƒ£ Run the canonical search script
python scripts/supplement_canonical_training.py


âœ… If the precomputed embedding space is present, youâ€™ll see:

ğŸ” Loading cached embeddings/index ...
âœ… FAISS index loaded from disk.


Then you can start searching immediately.

ğŸ§© Example
ğŸ§  Supplement Synonym Search (Canonical-Only)
âœ… Loaded 3120 canonical entries
âš™ï¸ Loading model: paraphrase-multilingual-MiniLM-L12-v2
âœ… FAISS index loaded from disk.

ğŸ” Enter ingredient name: A-vitamin

Results for 'A-vitamin':
======================================================================
Canonical: vitamin a
  Scores â†’ semantic: 0.91, lexical: 0.88, final: 0.90
----------------------------------------------------------------------
Canonical: vitamin a12
  Scores â†’ semantic: 0.43, lexical: 0.37, final: 0.42
----------------------------------------------------------------------

âš™ï¸ To rebuild embeddings (optional)

If you modify cleaned_supplements_highacc.csv or change the model:

Delete these four files:

data/embeddings_canonical.npy
data/index_canonical.faiss
data/index_lookup_canonical.csv
data/index_meta_canonical.json


Run:

python scripts/supplement_canonical_training.py


The script will rebuild and cache the new embedding space automatically.

ğŸ§® Model details

Embedding model: paraphrase-multilingual-MiniLM-L12-v2 (fast, multilingual)
You can switch to:

MODEL_NAME = "sentence-transformers/paraphrase-multilingual-mpnet-base-v2"


for higher accuracy (slower on CPU).

Scoring formula:

final_score = 0.7 * semantic_similarity + 0.3 * fuzzy_match


Adjust in ALPHA_SEM if you prefer more reliance on text similarity.

ğŸ§¹ Data preprocessing

Run:

python scripts/preprocess_high_accuracy.py


This script:

Merges your raw novel-food and pharma JSON files

Normalizes text (Unicode, accents, punctuation, dashes)

Removes generic terms (â€œextractâ€, â€œrootâ€, etc.)

Merges near-duplicate canonical names

Exports cleaned_supplements_highacc.csv for training

ğŸ“¦ Requirements
pandas
numpy
scikit-learn
sentence-transformers
faiss-cpu
rapidfuzz
tqdm

ğŸ§¾ License

MIT License Â© 2025
Created for multilingual supplement & ingredient normalization research.
